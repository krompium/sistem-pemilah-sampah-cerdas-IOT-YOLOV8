#!/usr/bin/env python3
"""
Test script untuk verifikasi instalasi dependencies
"""

import sys

def test_imports():
    """Test all required imports"""
    
    print("=" * 60)
    print("ğŸ§ª TESTING DEPENDENCIES")
    print("=" * 60)
    
    results = []
    
    # Test imports
    tests = [
        ("ultralytics", "YOLOv8"),
        ("cv2", "OpenCV"),
        ("numpy", "NumPy"),
        ("PIL", "Pillow"),
        ("yaml", "PyYAML"),
        ("matplotlib", "Matplotlib"),
        ("serial", "PySerial"),
    ]
    
    for module, name in tests:
        try:
            __import__(module)
            print(f"âœ… {name:20} - OK")
            results.append(True)
        except ImportError as e:
            print(f"âŒ {name:20} - MISSING")
            print(f"   Error: {e}")
            results.append(False)
    
    print("\n" + "=" * 60)
    
    if all(results):
        print("âœ… ALL DEPENDENCIES OK!")
        print("\nğŸš€ Ready untuk training & inference!")
        return True
    else:
        print("âŒ SOME DEPENDENCIES MISSING!")
        print("\nğŸ’¡ Install dengan:")
        print("   pip install -r requirements.txt")
        return False

def test_model():
    """Test if model file exists"""
    
    print("\n" + "=" * 60)
    print("ğŸ¤– CHECKING MODEL FILE")
    print("=" * 60)
    
    from pathlib import Path
    
    model_path = Path("models/best.pt")
    
    if model_path.exists():
        size_mb = model_path.stat().st_size / (1024 * 1024)
        print(f"âœ… Model found: {model_path}")
        print(f"   Size: {size_mb:.2f} MB")
        return True
    else:
        print(f"âš ï¸ Model not found: {model_path}")
        print("\nğŸ’¡ Langkah berikutnya:")
        print("   1. Training model di Google Colab")
        print("   2. Download best.pt")
        print("   3. Simpan di folder: models/best.pt")
        return False

def test_gpu():
    """Test GPU availability"""
    
    print("\n" + "=" * 60)
    print("ğŸ® CHECKING GPU")
    print("=" * 60)
    
    try:
        import torch
        
        print(f"PyTorch version: {torch.__version__}")
        
        if torch.cuda.is_available():
            print(f"âœ… GPU available: {torch.cuda.get_device_name(0)}")
            print(f"   CUDA version: {torch.version.cuda}")
            print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
            return True
        else:
            print("âš ï¸ GPU not available - will use CPU")
            print("\nğŸ’¡ CPU inference lebih lambat tapi tetap bisa jalan")
            return False
    except ImportError:
        print("âŒ PyTorch not installed")
        return False

def main():
    """Main test function"""
    
    print("\n")
    print("â•”" + "=" * 58 + "â•—")
    print("â•‘  ğŸ—‘ï¸  SISTEM PEMILAH SAMPAH CERDAS - SETUP TEST         â•‘")
    print("â•š" + "=" * 58 + "â•")
    print()
    
    # Test dependencies
    deps_ok = test_imports()
    
    # Test model
    model_ok = test_model()
    
    # Test GPU
    gpu_ok = test_gpu()
    
    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š SUMMARY")
    print("=" * 60)
    print(f"Dependencies: {'âœ… OK' if deps_ok else 'âŒ ERROR'}")
    print(f"Model file:   {'âœ… OK' if model_ok else 'âš ï¸ NOT FOUND'}")
    print(f"GPU:          {'âœ… AVAILABLE' if gpu_ok else 'âš ï¸ CPU ONLY'}")
    
    print("\n" + "=" * 60)
    
    if deps_ok:
        if model_ok:
            print("ğŸ‰ READY TO GO!")
            print("\nğŸš€ Run inference:")
            print("   python inference/laptop_inference.py")
        else:
            print("â³ ALMOST READY!")
            print("\nğŸ“ Next steps:")
            print("   1. Training di Colab")
            print("   2. Download best.pt")
            print("   3. Run inference")
    else:
        print("ğŸ”§ SETUP NEEDED!")
        print("\nğŸ“ Install dependencies:")
        print("   pip install -r requirements.txt")
    
    print("=" * 60)
    print()
    
    return deps_ok

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
