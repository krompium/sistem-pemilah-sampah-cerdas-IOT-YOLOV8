{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üóëÔ∏è SISTEM PEMILAH SAMPAH CERDAS - YOLOV8M TRAINING\n",
        "\n",
        "**Notebook Training untuk Google Colab Pro**\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Informasi Project\n",
        "\n",
        "- **Model**: YOLOv8m (Medium)\n",
        "- **Dataset**: Sampah Organik & Anorganik (dari Roboflow)\n",
        "- **Target Kelas**: 3 (Organik, Anorganik, B3)\n",
        "- **Hardware**: ESP32 + ESP32-CAM + Servo SG90\n",
        "- **Tujuan**: Tugas UAS\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° Quick Start\n",
        "\n",
        "1. Pastikan Runtime Type = **GPU** (Runtime > Change runtime type)\n",
        "2. Ganti `YOUR_API_KEY_HERE` dengan Roboflow API key Anda\n",
        "3. Run semua cells (Runtime > Run all)\n",
        "4. Download `best.pt` dari cell terakhir\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "intro_cell"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_gpu_check"
      },
      "outputs": [],
      "source": [
        "# üöÄ SISTEM PEMILAH SAMPAH CERDAS - YOLOV8M TRAINING\n",
        "# ================================================\n",
        "# Notebook ini untuk training model YOLOv8m di Google Colab Pro\n",
        "# Target: 3 Kelas (Organik, Anorganik, B3)\n",
        "# Hardware: ESP32 + ESP32-CAM + Servo + Sensor Ultrasonik\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üóëÔ∏è SISTEM PEMILAH SAMPAH CERDAS - TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check GPU\n",
        "import torch\n",
        "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(\"\\nüöÄ GPU siap digunakan untuk training!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è WARNING: GPU tidak terdeteksi!\")\n",
        "    print(\"   Pastikan Runtime Type = GPU di menu Runtime > Change runtime type\")\n",
        "\n",
        "# Install dependencies\n",
        "print(\"\\nüì¶ Installing dependencies...\")\n",
        "!pip install ultralytics roboflow -q\n",
        "print(\"‚úÖ Dependencies installed!\")\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "from ultralytics import YOLO\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üíæ MOUNT GOOGLE DRIVE\n",
        "# Untuk menyimpan hasil training secara permanen\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Buat folder project di Google Drive\n",
        "PROJECT_DIR = Path('/content/drive/MyDrive/sistem-pemilah-sampah')\n",
        "PROJECT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive mounted!\")\n",
        "print(f\"üìÅ Project directory: {PROJECT_DIR}\")\n",
        "\n",
        "# Pindah ke direktori kerja\n",
        "os.chdir('/content')\n",
        "print(f\"üìÇ Working directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä DOWNLOAD DATASET DARI ROBOFLOW\n",
        "# Dataset: Sampah Organik, Anorganik, dan B3\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üì• DOWNLOADING DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ‚ö†Ô∏è GANTI DENGAN API KEY ANDA!\n",
        "# Cara mendapatkan API key:\n",
        "# 1. Daftar di https://roboflow.com (GRATIS)\n",
        "# 2. Login ke https://app.roboflow.com\n",
        "# 3. Klik Settings (kiri bawah) > Roboflow API\n",
        "# 4. Copy Private API Key\n",
        "# 5. Paste di bawah ini\n",
        "\n",
        "ROBOFLOW_API_KEY = \"YOUR_API_KEY_HERE\"  # üëà GANTI INI!\n",
        "\n",
        "if ROBOFLOW_API_KEY == \"YOUR_API_KEY_HERE\":\n",
        "    print(\"\\n‚ö†Ô∏è ERROR: API Key belum diganti!\")\n",
        "    print(\"   Silakan dapatkan API key dari:\")\n",
        "    print(\"   https://app.roboflow.com/settings/api\")\n",
        "    print(\"\\n   Atau download dataset manual:\")\n",
        "    print(\"   1. Buka: https://universe.roboflow.com/siscer-project/sampah-organik-dan-anorganik\")\n",
        "    print(\"   2. Klik 'Download Dataset'\")\n",
        "    print(\"   3. Pilih format: YOLOv8\")\n",
        "    print(\"   4. Upload ZIP ke Colab\")\n",
        "else:\n",
        "    try:\n",
        "        # Initialize Roboflow\n",
        "        rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "        \n",
        "        # Download dataset Sampah Organik & Anorganik\n",
        "        print(\"\\nüì• Downloading dataset dari Roboflow...\")\n",
        "        project = rf.workspace(\"siscer-project\").project(\"sampah-organik-dan-anorganik\")\n",
        "        dataset = project.version(3).download(\"yolov8\")\n",
        "        \n",
        "        DATASET_PATH = dataset.location\n",
        "        print(f\"\\n‚úÖ Dataset berhasil didownload!\")\n",
        "        print(f\"üìÅ Location: {DATASET_PATH}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error: {e}\")\n",
        "        print(\"\\nüí° Solusi:\")\n",
        "        print(\"   1. Cek API key sudah benar\")\n",
        "        print(\"   2. Pastikan internet stabil\")\n",
        "        print(\"   3. Atau download manual (lihat instruksi di atas)\")"
      ],
      "metadata": {
        "id": "download_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç EKSPLORASI DATASET\n",
        "# Melihat struktur dan isi dataset\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìä DATASET EXPLORATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Baca data.yaml\n",
        "yaml_path = Path(DATASET_PATH) / 'data.yaml'\n",
        "with open(yaml_path, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "print(f\"\\nüìÑ Dataset Configuration:\")\n",
        "print(f\"   Classes: {data_config['nc']}\")\n",
        "print(f\"   Names: {data_config['names']}\")\n",
        "\n",
        "# Hitung jumlah gambar\n",
        "train_images = list(Path(DATASET_PATH).glob('train/images/*.jpg')) + \\\n",
        "               list(Path(DATASET_PATH).glob('train/images/*.png'))\n",
        "val_images = list(Path(DATASET_PATH).glob('valid/images/*.jpg')) + \\\n",
        "             list(Path(DATASET_PATH).glob('valid/images/*.png'))\n",
        "\n",
        "print(f\"\\nüìà Dataset Statistics:\")\n",
        "print(f\"   Training images: {len(train_images)}\")\n",
        "print(f\"   Validation images: {len(val_images)}\")\n",
        "print(f\"   Total: {len(train_images) + len(val_images)}\")\n",
        "\n",
        "# Tampilkan sample gambar\n",
        "print(\"\\nüñºÔ∏è Sample Images:\")\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "sample_images = random.sample(train_images, min(6, len(train_images)))\n",
        "for idx, img_path in enumerate(sample_images):\n",
        "    img = Image.open(img_path)\n",
        "    axes[idx].imshow(img)\n",
        "    axes[idx].set_title(img_path.name, fontsize=10)\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Update data.yaml untuk 3 kelas (jika perlu)\n",
        "# Catatan: Dataset Roboflow biasanya hanya 2 kelas (organik & anorganik)\n",
        "# Anda perlu menambahkan kelas B3 secara manual jika diperlukan\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è CATATAN PENTING:\")\n",
        "print(\"   Dataset Roboflow biasanya hanya memiliki 2 kelas:\")\n",
        "print(\"   - Organik\")\n",
        "print(\"   - Anorganik\")\n",
        "print(\"\\n   Untuk kelas B3 (Bahan Berbahaya & Beracun):\")\n",
        "print(\"   - Tambahkan gambar B3 secara manual\")\n",
        "print(\"   - Atau lanjutkan training dengan 2 kelas dulu\")\n",
        "print(\"\\n   Untuk UAS besok, 2 kelas sudah cukup!\")\n",
        "print(\"   B3 bisa ditambahkan nanti.\")"
      ],
      "metadata": {
        "id": "explore_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚öôÔ∏è KONFIGURASI TRAINING\n",
        "# Setup parameter training untuk YOLOv8m\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "CONFIG = {\n",
        "    # Model\n",
        "    'model': 'yolov8m.pt',      # YOLOv8 Medium (balance accuracy & speed)\n",
        "    \n",
        "    # Training\n",
        "    'epochs': 150,               # Jumlah epoch (bisa dikurangi jika waktu terbatas)\n",
        "    'imgsz': 640,                # Ukuran gambar\n",
        "    'batch': 32,                 # Batch size untuk Colab Pro (T4/A100)\n",
        "    'device': 0,                 # GPU device\n",
        "    \n",
        "    # Optimization\n",
        "    'optimizer': 'AdamW',        # Optimizer (AdamW lebih baik dari Adam)\n",
        "    'lr0': 0.001,               # Initial learning rate\n",
        "    'lrf': 0.01,                # Final learning rate (fraction of lr0)\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'patience': 50,              # Early stopping patience\n",
        "    \n",
        "    # Augmentation\n",
        "    'hsv_h': 0.015,             # Hue augmentation\n",
        "    'hsv_s': 0.7,               # Saturation augmentation\n",
        "    'hsv_v': 0.4,               # Value augmentation\n",
        "    'degrees': 10.0,            # Rotation degree\n",
        "    'translate': 0.1,           # Translation\n",
        "    'scale': 0.5,               # Scaling\n",
        "    'shear': 0.0,               # Shear\n",
        "    'perspective': 0.0,         # Perspective\n",
        "    'flipud': 0.0,              # Flip up-down\n",
        "    'fliplr': 0.5,              # Flip left-right\n",
        "    'mosaic': 1.0,              # Mosaic augmentation\n",
        "    'mixup': 0.15,              # Mixup augmentation\n",
        "    \n",
        "    # Project\n",
        "    'project': 'pemilah-sampah',\n",
        "    'name': 'yolov8m_organik_anorganik',\n",
        "}\n",
        "\n",
        "print(\"\\nüìã Training Parameters:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"   {key:15} : {value}\")\n",
        "\n",
        "print(\"\\nüí° Tips:\")\n",
        "print(\"   - Epochs 150 = ~1-1.5 jam di Colab Pro\")\n",
        "print(\"   - Bisa dikurangi jadi 100 jika waktu terbatas\")\n",
        "print(\"   - Model terbaik otomatis tersimpan di 'best.pt'\")"
      ],
      "metadata": {
        "id": "training_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ START TRAINING\n",
        "# Proses training dimulai!\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üöÄ MEMULAI TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚è∞ Estimasi waktu: 1-2 jam (tergantung GPU & dataset size)\")\n",
        "print(\"üí° Tips: Biarkan jalan, bisa sambil istirahat!\\n\")\n",
        "\n",
        "# Load model\n",
        "model = YOLO(CONFIG['model'])\n",
        "\n",
        "# Start training\n",
        "results = model.train(\n",
        "    data=str(yaml_path),\n",
        "    epochs=CONFIG['epochs'],\n",
        "    imgsz=CONFIG['imgsz'],\n",
        "    batch=CONFIG['batch'],\n",
        "    device=CONFIG['device'],\n",
        "    \n",
        "    # Optimization\n",
        "    optimizer=CONFIG['optimizer'],\n",
        "    lr0=CONFIG['lr0'],\n",
        "    lrf=CONFIG['lrf'],\n",
        "    momentum=CONFIG['momentum'],\n",
        "    weight_decay=CONFIG['weight_decay'],\n",
        "    patience=CONFIG['patience'],\n",
        "    \n",
        "    # Augmentation\n",
        "    hsv_h=CONFIG['hsv_h'],\n",
        "    hsv_s=CONFIG['hsv_s'],\n",
        "    hsv_v=CONFIG['hsv_v'],\n",
        "    degrees=CONFIG['degrees'],\n",
        "    translate=CONFIG['translate'],\n",
        "    scale=CONFIG['scale'],\n",
        "    shear=CONFIG['shear'],\n",
        "    perspective=CONFIG['perspective'],\n",
        "    flipud=CONFIG['flipud'],\n",
        "    fliplr=CONFIG['fliplr'],\n",
        "    mosaic=CONFIG['mosaic'],\n",
        "    mixup=CONFIG['mixup'],\n",
        "    \n",
        "    # Validation & Saving\n",
        "    val=True,\n",
        "    save=True,\n",
        "    save_period=10,\n",
        "    plots=True,\n",
        "    verbose=True,\n",
        "    \n",
        "    # Project\n",
        "    project=CONFIG['project'],\n",
        "    name=CONFIG['name'],\n",
        "    exist_ok=False,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ TRAINING SELESAI!\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "start_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìà EVALUASI MODEL\n",
        "# Melihat performa model pada validation set\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä EVALUASI MODEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Evaluate\n",
        "metrics = model.val()\n",
        "\n",
        "# Display metrics\n",
        "print(f\"\\nüìà HASIL EVALUASI:\")\n",
        "print(f\"   mAP50      : {metrics.box.map50:.4f}\")\n",
        "print(f\"   mAP50-95   : {metrics.box.map:.4f}\")\n",
        "print(f\"   Precision  : {metrics.box.mp:.4f}\")\n",
        "print(f\"   Recall     : {metrics.box.mr:.4f}\")\n",
        "\n",
        "# Per-class metrics\n",
        "if hasattr(metrics.box, 'ap50'):\n",
        "    print(f\"\\nüìä Metrics per Kelas:\")\n",
        "    class_names = data_config['names']\n",
        "    for i, name in enumerate(class_names):\n",
        "        if i < len(metrics.box.ap50):\n",
        "            print(f\"   {name:12} - mAP50: {metrics.box.ap50[i]:.4f}\")\n",
        "\n",
        "print(\"\\nüí° Interpretasi:\")\n",
        "print(\"   mAP50 > 0.85 = BAGUS SEKALI! üéâ\")\n",
        "print(\"   mAP50 > 0.70 = CUKUP BAIK ‚úÖ\")\n",
        "print(\"   mAP50 < 0.70 = Perlu improvement üìà\")"
      ],
      "metadata": {
        "id": "evaluation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä VISUALISASI HASIL TRAINING\n",
        "# Melihat training plots, confusion matrix, dan prediksi\n",
        "\n",
        "run_dir = Path(CONFIG['project']) / CONFIG['name']\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìä VISUALISASI HASIL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Training Results\n",
        "results_img = run_dir / 'results.png'\n",
        "if results_img.exists():\n",
        "    print(\"\\nüìà 1. Training Metrics (Loss, Precision, Recall, mAP):\")\n",
        "    display(Image(filename=str(results_img)))\n",
        "\n",
        "# 2. Confusion Matrix\n",
        "confusion_img = run_dir / 'confusion_matrix.png'\n",
        "if confusion_img.exists():\n",
        "    print(\"\\nüéØ 2. Confusion Matrix:\")\n",
        "    display(Image(filename=str(confusion_img)))\n",
        "\n",
        "# 3. Sample Predictions\n",
        "val_batch = run_dir / 'val_batch0_pred.jpg'\n",
        "if val_batch.exists():\n",
        "    print(\"\\nüîç 3. Sample Predictions pada Validation Set:\")\n",
        "    display(Image(filename=str(val_batch)))\n",
        "\n",
        "print(\"\\n‚úÖ Semua visualisasi ditampilkan!\")"
      ],
      "metadata": {
        "id": "visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß™ TEST INFERENCE\n",
        "# Mencoba model pada gambar random dari validation set\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üß™ TEST INFERENCE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load best model\n",
        "best_model = YOLO(run_dir / 'weights' / 'best.pt')\n",
        "\n",
        "# Test pada beberapa gambar random\n",
        "test_images = random.sample(val_images, min(4, len(val_images)))\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
        "axes = axes.ravel()\n",
        "\n",
        "print(\"\\nüîç Hasil Deteksi:\\n\")\n",
        "\n",
        "for idx, img_path in enumerate(test_images):\n",
        "    # Predict\n",
        "    results = best_model(str(img_path), conf=0.5)\n",
        "    \n",
        "    # Plot\n",
        "    annotated = results[0].plot()\n",
        "    axes[idx].imshow(annotated[..., ::-1])  # BGR to RGB\n",
        "    axes[idx].set_title(f\"Prediction: {img_path.name}\", fontsize=12)\n",
        "    axes[idx].axis('off')\n",
        "    \n",
        "    # Print detections\n",
        "    if len(results[0].boxes) > 0:\n",
        "        for box in results[0].boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            class_name = data_config['names'][cls]\n",
        "            print(f\"   üì∏ {img_path.name}\")\n",
        "            print(f\"      ‚ûú {class_name.upper()} ({conf:.2%})\\n\")\n",
        "    else:\n",
        "        print(f\"   üì∏ {img_path.name}\")\n",
        "        print(f\"      ‚ûú Tidak ada deteksi\\n\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Test inference selesai!\")"
      ],
      "metadata": {
        "id": "test_inference"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ EXPORT MODEL\n",
        "# Export ke berbagai format untuk deployment\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üì¶ EXPORT MODEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüîÑ Exporting model ke berbagai format...\")\n",
        "print(\"   (Proses ini memakan waktu 2-5 menit)\\n\")\n",
        "\n",
        "# 1. ONNX (untuk deployment umum)\n",
        "print(\"üì§ 1. Exporting to ONNX...\")\n",
        "try:\n",
        "    best_model.export(format='onnx', imgsz=640)\n",
        "    print(\"   ‚úÖ ONNX export complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "# 2. TensorFlow Lite (untuk Raspberry Pi / Mobile)\n",
        "print(\"\\nüì§ 2. Exporting to TFLite...\")\n",
        "try:\n",
        "    best_model.export(format='tflite', imgsz=640)\n",
        "    print(\"   ‚úÖ TFLite export complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "# 3. TorchScript (untuk PyTorch deployment)\n",
        "print(\"\\nüì§ 3. Exporting to TorchScript...\")\n",
        "try:\n",
        "    best_model.export(format='torchscript', imgsz=640)\n",
        "    print(\"   ‚úÖ TorchScript export complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ EXPORT SELESAI!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nFile yang tersedia:\")\n",
        "print(f\"   üìÅ {run_dir}/weights/\")\n",
        "print(\"      - best.pt (PyTorch)\")\n",
        "print(\"      - best.onnx (ONNX)\")\n",
        "print(\"      - best.tflite (TensorFlow Lite)\")\n",
        "print(\"      - best.torchscript (TorchScript)\")"
      ],
      "metadata": {
        "id": "export_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üíæ COPY HASIL KE GOOGLE DRIVE\n",
        "# Agar hasil training tidak hilang saat Colab disconnect\n",
        "\n",
        "import shutil\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üíæ MENYIMPAN KE GOOGLE DRIVE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Path tujuan di Google Drive\n",
        "drive_save_path = PROJECT_DIR / CONFIG['name']\n",
        "\n",
        "print(f\"\\nüìÅ Copying files...\")\n",
        "print(f\"   From: {run_dir}\")\n",
        "print(f\"   To: {drive_save_path}\")\n",
        "\n",
        "# Hapus folder lama jika ada\n",
        "if drive_save_path.exists():\n",
        "    shutil.rmtree(drive_save_path)\n",
        "\n",
        "# Copy semua hasil\n",
        "shutil.copytree(run_dir, drive_save_path)\n",
        "\n",
        "print(f\"\\n‚úÖ HASIL TRAINING TERSIMPAN DI GOOGLE DRIVE!\")\n",
        "print(f\"üìÅ Location: {drive_save_path}\")\n",
        "\n",
        "print(\"\\nüì¶ File yang tersimpan:\")\n",
        "print(\"   ‚úÖ best.pt - Model terbaik\")\n",
        "print(\"   ‚úÖ last.pt - Model terakhir\")\n",
        "print(\"   ‚úÖ best.onnx - Format ONNX\")\n",
        "print(\"   ‚úÖ best.tflite - Format TFLite\")\n",
        "print(\"   ‚úÖ results.png - Training plots\")\n",
        "print(\"   ‚úÖ confusion_matrix.png - Confusion matrix\")\n",
        "print(\"   ‚úÖ Dan semua file hasil training lainnya\")\n",
        "\n",
        "print(\"\\nüí° File ini akan tetap ada meskipun Colab disconnect!\")"
      ],
      "metadata": {
        "id": "save_to_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì• DOWNLOAD MODEL\n",
        "# Download model ke komputer lokal\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üì• DOWNLOAD MODEL KE KOMPUTER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüí° Pilih file yang ingin di-download:\\n\")\n",
        "\n",
        "download_files = {\n",
        "    '1': (run_dir / 'weights' / 'best.pt', 'Model PyTorch (WAJIB!)'),\n",
        "    '2': (run_dir / 'weights' / 'best.onnx', 'Model ONNX'),\n",
        "    '3': (run_dir / 'weights' / 'best.tflite', 'Model TFLite'),\n",
        "    '4': (run_dir / 'results.png', 'Training Results'),\n",
        "    '5': (run_dir / 'confusion_matrix.png', 'Confusion Matrix'),\n",
        "}\n",
        "\n",
        "# Download best.pt (WAJIB untuk inference!)\n",
        "print(\"‚¨áÔ∏è Downloading best.pt (Model utama)...\")\n",
        "best_pt = run_dir / 'weights' / 'best.pt'\n",
        "if best_pt.exists():\n",
        "    files.download(str(best_pt))\n",
        "    print(\"‚úÖ best.pt downloaded!\")\n",
        "else:\n",
        "    print(\"‚ùå File tidak ditemukan!\")\n",
        "\n",
        "# Download ONNX (opsional, untuk deployment)\n",
        "print(\"\\n‚¨áÔ∏è Downloading best.onnx...\")\n",
        "best_onnx = run_dir / 'weights' / 'best.onnx'\n",
        "if best_onnx.exists():\n",
        "    files.download(str(best_onnx))\n",
        "    print(\"‚úÖ best.onnx downloaded!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ DOWNLOAD SELESAI!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nüìù Langkah selanjutnya:\")\n",
        "print(\"   1. Simpan file best.pt di folder models/\")\n",
        "print(\"   2. Gunakan untuk inference di laptop\")\n",
        "print(\"   3. Integrasikan dengan ESP32-CAM\")"
      ],
      "metadata": {
        "id": "download_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä SUMMARY & NEXT STEPS\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéâ TRAINING COMPLETE - SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nüìÅ Project: {CONFIG['project']}\")\n",
        "print(f\"üìù Name: {CONFIG['name']}\")\n",
        "print(f\"ü§ñ Model: {CONFIG['model']}\")\n",
        "print(f\"üìä Dataset: {len(train_images)} train, {len(val_images)} val\")\n",
        "print(f\"‚öôÔ∏è Epochs: {CONFIG['epochs']}\")\n",
        "\n",
        "print(f\"\\nüìà Final Metrics:\")\n",
        "print(f\"   mAP50      : {metrics.box.map50:.4f}\")\n",
        "print(f\"   mAP50-95   : {metrics.box.map:.4f}\")\n",
        "print(f\"   Precision  : {metrics.box.mp:.4f}\")\n",
        "print(f\"   Recall     : {metrics.box.mr:.4f}\")\n",
        "\n",
        "print(f\"\\nüíæ Saved to:\")\n",
        "print(f\"   Google Drive: {drive_save_path}\")\n",
        "print(f\"   Colab: {run_dir}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üöÄ NEXT STEPS - UNTUK UAS BESOK:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\"\"\n",
        "1. ‚úÖ Download best.pt (sudah dilakukan di cell sebelumnya)\n",
        "2. üìÅ Simpan di folder: models/best.pt\n",
        "3. üñ•Ô∏è Setup inference script di laptop\n",
        "4. üîß Setup ESP32 + ESP32-CAM hardware\n",
        "5. üì± Setup Blynk untuk monitoring\n",
        "6. üß™ Test dengan sampah asli\n",
        "7. üé• Record video demo\n",
        "8. üìä Prepare presentasi UAS\n",
        "\n",
        "üí° TIP PENTING:\n",
        "   - Jika waktu terbatas, fokus ke inference di laptop dulu\n",
        "   - ESP32-CAM bisa pakai webcam sebagai backup\n",
        "   - Blynk bisa di-skip jika tidak sempat\n",
        "   - Yang penting: MODEL TRAINED + BISA DETEKSI = NILAI BAGUS!\n",
        "\n",
        "üéì GOOD LUCK UNTUK UAS BESOK! üöÄ\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "summary"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
